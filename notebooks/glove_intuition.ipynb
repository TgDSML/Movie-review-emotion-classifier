{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "adeefff1",
   "metadata": {},
   "source": [
    "Intuitive example and used it to show how the glove NLP embedding works and also to download the GloVe dataset from Stanford's NLP repository for use in our projects feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ad9a1bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1a384821",
   "metadata": {},
   "outputs": [],
   "source": [
    "#simple example of a list of words to be tokenized\n",
    "texts = ['text', 'the', 'leader', 'prime', 'natural', 'language']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3d288a9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique words in dictionary = 6\n",
      "Dictionary is = {'text': 1, 'the': 2, 'leader': 3, 'prime': 4, 'natural': 5, 'language': 6}\n"
     ]
    }
   ],
   "source": [
    "#create a tokenizer and feed it the list\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(texts)\n",
    "\n",
    "print(\"Number of unique words in dictionary =\", len(tokenizer.word_index))\n",
    "print(\"Dictionary is =\", tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c7133428",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embedding_for_vocab(filepath, word_index, embedding_dim):\n",
    "    vocab_size = len(word_index) + 1  # +1 for padding token (index 0)\n",
    "    embedding_matrix_vocab = np.zeros((vocab_size, embedding_dim))\n",
    "\n",
    "    with open(filepath, encoding=\"utf8\") as f:\n",
    "        for line in f:\n",
    "            word, *vector = line.split()\n",
    "            if word in word_index:\n",
    "                idx = word_index[word]\n",
    "                embedding_matrix_vocab[idx] = np.array(vector, dtype=np.float32)[:embedding_dim]\n",
    "\n",
    "    return embedding_matrix_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3145ebc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found: glove.6B.100d.txt\n",
      "Found: glove.6B.200d.txt\n",
      "Found: glove.6B.300d.txt\n",
      "Found: glove.6B.50d.txt\n",
      "Found: glove.6B.zip\n"
     ]
    }
   ],
   "source": [
    "#This cell downloads the GloVe dataset from Stanford's NLP repository and unzips it. In case that the file is already saved locally the cell prints Found: glove.6B*\n",
    "import urllib.request\n",
    "import zipfile\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "zip_path = Path(\"glove.6B.zip\")\n",
    "extract_dir = Path(\".\")\n",
    "\n",
    "url = \"http://nlp.stanford.edu/data/glove.6B.zip\"\n",
    "if not zip_path.exists():\n",
    "    urllib.request.urlretrieve(url, zip_path)\n",
    "\n",
    "with zipfile.ZipFile(zip_path, \"r\") as zip_ref:\n",
    "    zip_ref.extractall(extract_dir)\n",
    "\n",
    "for file in os.listdir(extract_dir):\n",
    "    if file.startswith(\"glove.6B\"):\n",
    "        print(f\"Found: {file}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cb80be0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 50 # match this with glove file\n",
    "glove_path = './glove.6B.50d.txt'\n",
    "\n",
    "embedding_matrix_vocab = embedding_for_vocab(glove_path, tokenizer.word_index, embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "81e3d412",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dense vector for word with index 1 => [ 0.32615     0.36686    -0.0074905  -0.37553     0.66715002  0.21646\n",
      " -0.19801    -1.10010004 -0.42221001  0.10574    -0.31292     0.50953001\n",
      "  0.55774999  0.12019     0.31441    -0.25042999 -1.06369996 -1.32130003\n",
      "  0.87797999 -0.24627     0.27379    -0.51091999  0.49324     0.52243\n",
      "  1.16359997 -0.75322998 -0.48052999 -0.11259    -0.54595    -0.83920997\n",
      "  2.98250008 -1.19159997 -0.51958001 -0.39365    -0.1419     -0.026977\n",
      "  0.66295999  0.16574    -1.1681      0.14443     1.63049996 -0.17216\n",
      " -0.17436001 -0.01049    -0.17794     0.93076003  1.0381      0.94265997\n",
      " -0.14805    -0.61109   ]\n"
     ]
    }
   ],
   "source": [
    "first_word_index = 1  # Tokenizer indexes start from 1\n",
    "print(\"Dense vector for word with index 1 =>\", embedding_matrix_vocab[first_word_index])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.10.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
